{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/Dokumente/GitHub/Entity-Role-Detection-in-Memes/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from meme_entity_detection.dataset.data_module import DataModule\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from spacy.cli import download\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Download the large English model if it is not already installed\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "except OSError:\n",
    "    download(\"en_core_web_lg\")\n",
    "    \n",
    "    \n",
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>original</th>\n",
       "      <th>dataset</th>\n",
       "      <th>image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realtor: can you see yourself being quarantine...</td>\n",
       "      <td>REALTOR: CAN YOU SEE\\nYOURSELF BEING QUARANTIN...</td>\n",
       "      <td>train</td>\n",
       "      <td>covid_memes_4999.png</td>\n",
       "      <td>../../../data/HVVMemes/images/covid_memes_4999...</td>\n",
       "      <td>[realtor, quarantine, quaranitned]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when you connect your charger on 1% chárge but...</td>\n",
       "      <td>When you connect your charger on\\n1% chárge bu...</td>\n",
       "      <td>train</td>\n",
       "      <td>covid_memes_4355.png</td>\n",
       "      <td>../../../data/HVVMemes/images/covid_memes_4355...</td>\n",
       "      <td>[charger, phone, cats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i tyt tyt reacts: first presidential debate ne...</td>\n",
       "      <td>I TYT TYT REACTS: FIRST PRESIDENTIAL DEBATE\\nN...</td>\n",
       "      <td>train</td>\n",
       "      <td>memes_4435.png</td>\n",
       "      <td>../../../data/HVVMemes/images/memes_4435.png</td>\n",
       "      <td>[presidential debate, joe biden, donald trump,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the democratic party is socialist. i am the de...</td>\n",
       "      <td>The Democratic Party is socialist.\\nI am the D...</td>\n",
       "      <td>train</td>\n",
       "      <td>memes_1692.png</td>\n",
       "      <td>../../../data/HVVMemes/images/memes_1692.png</td>\n",
       "      <td>[democratic party, socialist, joe biden, donal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>every disaster movie starts with the governmen...</td>\n",
       "      <td>EVERY\\nDISASTER\\nMOVIE STARTS\\nWITH THE\\nGOVER...</td>\n",
       "      <td>train</td>\n",
       "      <td>covid_memes_1094.png</td>\n",
       "      <td>../../../data/HVVMemes/images/covid_memes_1094...</td>\n",
       "      <td>[government, scientist, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6711</th>\n",
       "      <td>600 recorded reguests for additional security ...</td>\n",
       "      <td>600 recorded reguests for\\nadditional security...</td>\n",
       "      <td>test</td>\n",
       "      <td>memes_1585.png</td>\n",
       "      <td>../../../data/HVVMemes/images/memes_1585.png</td>\n",
       "      <td>[hillary clinton, amb chris stevens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6712</th>\n",
       "      <td>i am the democrat party! if you say so joe!</td>\n",
       "      <td>I AM THE DEMOCRAT PARTY!\\nIF YOU SAY SO JOE!\\n</td>\n",
       "      <td>test</td>\n",
       "      <td>memes_1312.png</td>\n",
       "      <td>../../../data/HVVMemes/images/memes_1312.png</td>\n",
       "      <td>[bernie sanders, kamala harris, joe biden, dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>donald trump's incompetence is becoming all to...</td>\n",
       "      <td>Donald Trump's incompetence is\\nbecoming all t...</td>\n",
       "      <td>test</td>\n",
       "      <td>covid_memes_5577.png</td>\n",
       "      <td>../../../data/HVVMemes/images/covid_memes_5577...</td>\n",
       "      <td>[donald trump, us, covid19, mike pence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6714</th>\n",
       "      <td>rammys oflammys 12h hini vs covid-19 cases - c...</td>\n",
       "      <td>Rammys Oflammys 12h\\nHINI Vs Covid-19\\nCases -...</td>\n",
       "      <td>test</td>\n",
       "      <td>covid_memes_5583.png</td>\n",
       "      <td>../../../data/HVVMemes/images/covid_memes_5583...</td>\n",
       "      <td>[h1n1, h1n1 vs covid19, covid19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6715</th>\n",
       "      <td>donald trump, covid 19 and the end of mdis ica...</td>\n",
       "      <td>Donald Trump, COVID 19\\nand the end of MDIS\\nI...</td>\n",
       "      <td>test</td>\n",
       "      <td>covid_memes_5625.png</td>\n",
       "      <td>../../../data/HVVMemes/images/covid_memes_5625...</td>\n",
       "      <td>[mdis, donald trump, covid19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6716 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     realtor: can you see yourself being quarantine...   \n",
       "1     when you connect your charger on 1% chárge but...   \n",
       "2     i tyt tyt reacts: first presidential debate ne...   \n",
       "3     the democratic party is socialist. i am the de...   \n",
       "4     every disaster movie starts with the governmen...   \n",
       "...                                                 ...   \n",
       "6711  600 recorded reguests for additional security ...   \n",
       "6712       i am the democrat party! if you say so joe!    \n",
       "6713  donald trump's incompetence is becoming all to...   \n",
       "6714  rammys oflammys 12h hini vs covid-19 cases - c...   \n",
       "6715  donald trump, covid 19 and the end of mdis ica...   \n",
       "\n",
       "                                               original dataset  \\\n",
       "0     REALTOR: CAN YOU SEE\\nYOURSELF BEING QUARANTIN...   train   \n",
       "1     When you connect your charger on\\n1% chárge bu...   train   \n",
       "2     I TYT TYT REACTS: FIRST PRESIDENTIAL DEBATE\\nN...   train   \n",
       "3     The Democratic Party is socialist.\\nI am the D...   train   \n",
       "4     EVERY\\nDISASTER\\nMOVIE STARTS\\nWITH THE\\nGOVER...   train   \n",
       "...                                                 ...     ...   \n",
       "6711  600 recorded reguests for\\nadditional security...    test   \n",
       "6712     I AM THE DEMOCRAT PARTY!\\nIF YOU SAY SO JOE!\\n    test   \n",
       "6713  Donald Trump's incompetence is\\nbecoming all t...    test   \n",
       "6714  Rammys Oflammys 12h\\nHINI Vs Covid-19\\nCases -...    test   \n",
       "6715  Donald Trump, COVID 19\\nand the end of MDIS\\nI...    test   \n",
       "\n",
       "                     image                                         image_path  \\\n",
       "0     covid_memes_4999.png  ../../../data/HVVMemes/images/covid_memes_4999...   \n",
       "1     covid_memes_4355.png  ../../../data/HVVMemes/images/covid_memes_4355...   \n",
       "2           memes_4435.png       ../../../data/HVVMemes/images/memes_4435.png   \n",
       "3           memes_1692.png       ../../../data/HVVMemes/images/memes_1692.png   \n",
       "4     covid_memes_1094.png  ../../../data/HVVMemes/images/covid_memes_1094...   \n",
       "...                    ...                                                ...   \n",
       "6711        memes_1585.png       ../../../data/HVVMemes/images/memes_1585.png   \n",
       "6712        memes_1312.png       ../../../data/HVVMemes/images/memes_1312.png   \n",
       "6713  covid_memes_5577.png  ../../../data/HVVMemes/images/covid_memes_5577...   \n",
       "6714  covid_memes_5583.png  ../../../data/HVVMemes/images/covid_memes_5583...   \n",
       "6715  covid_memes_5625.png  ../../../data/HVVMemes/images/covid_memes_5625...   \n",
       "\n",
       "                                                   word  \n",
       "0                    [realtor, quarantine, quaranitned]  \n",
       "1                                [charger, phone, cats]  \n",
       "2     [presidential debate, joe biden, donald trump,...  \n",
       "3     [democratic party, socialist, joe biden, donal...  \n",
       "4                       [government, scientist, people]  \n",
       "...                                                 ...  \n",
       "6711               [hillary clinton, amb chris stevens]  \n",
       "6712  [bernie sanders, kamala harris, joe biden, dem...  \n",
       "6713            [donald trump, us, covid19, mike pence]  \n",
       "6714                   [h1n1, h1n1 vs covid19, covid19]  \n",
       "6715                      [mdis, donald trump, covid19]  \n",
       "\n",
       "[6716 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "\n",
    "import meme_entity_detection.dataset\n",
    "\n",
    "data_dir = Path(\"../../../data/HVVMemes/\")\n",
    "dataset = meme_entity_detection.dataset.DataModule(data_dir, balance_train_dataset=False)\n",
    "dataset.setup(\"_\")\n",
    "IPython.display.clear_output(wait=False)\n",
    "\n",
    "train_df = dataset.train_dataset.data_df\n",
    "validation_df = dataset.validation_dataset.data_df\n",
    "test_df = dataset.test_dataset.data_df\n",
    "\n",
    "# Concatenating all dataframes to get a combined view\n",
    "combined_df = pd.concat([\n",
    "    train_df.assign(dataset='train'),\n",
    "    validation_df.assign(dataset='validation'),\n",
    "    test_df.assign(dataset='test')\n",
    "])[[\"sentence\", \"original\", \"dataset\", \"image\", \"word\"]].drop_duplicates()\n",
    "\n",
    "combined_df[\"image_path\"] = str(data_dir) + \"/images/\" + combined_df[\"image\"]\n",
    "\n",
    "entities_in_image = combined_df.groupby(\"image\")[\"word\"].apply(list).reset_index()\n",
    "combined_df = combined_df[[\"sentence\", \"original\", \"dataset\", \"image\", \"image_path\"]].drop_duplicates()\n",
    "combined_df = combined_df.merge(entities_in_image, on=\"image\")\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = input(\"Please insert your api key:\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path: list):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "  \n",
    "def build_prompt(entities):\n",
    "  entities_dict = {entity: \"fill in the class here\" for entity in entities}\n",
    "\n",
    "\n",
    "  json_format = \"\"\"{\"OCR\": \"OCR OF THE IMAGE\",\n",
    "  \"IMAGE_DESCRIPTION: \"DESCRIPTION_OF_IMAGE_CONTENTS\",\n",
    "  \"CLASSIFICATION\": \"\"\"+str(entities_dict).replace('\",', '\",\\n') + \"\"\"\n",
    "  }\"\"\"\n",
    "                              \n",
    "  text = f\"\"\"Process the image and fill the following json-object in the follwing schema. \n",
    "  You should OCR, image description and classification. Do net return anything else than the json.\n",
    "  Do not change the format of the json. If you can not fill in the json, return a None inside of the json:\n",
    "                      \n",
    "  For the classification note that each entitly must exactly have one class.\n",
    "  Do not change the name of the entities, even if they are misspelled.\n",
    "\n",
    "  This task emphasizes detecting which entities are glorified, vilified or victimized, within a meme. Assuming the frame of reference as the meme author’s perspective, the objective is to classify for a given pair of a meme and an entity, whether the entity is being referenced as Hero vs. Villain vs. Victim vs. Other, within that meme.\n",
    "  Definition of the entity classes:\n",
    "\n",
    "      Hero: The entity is presented in a positive light. Glorified for their actions conveyed via the meme or gathered from background context\n",
    "      Villain: The entity is portrayed negatively, e.g., in an association with adverse traits like wickedness, cruelty, hypocrisy, etc.\n",
    "      Victim: The entity is portrayed as suffering the negative impact of someone else’s actions or conveyed implicitly within the meme.\n",
    "      Other: The entity is not a hero, a villain, or a victim.   \n",
    "              \n",
    "  The classes you can choose from are:\n",
    "  \"other\", \"villain\", \"victim\", \"hero\"\n",
    "                      \n",
    "                      \n",
    "  Here is the json template:\n",
    "                      \n",
    "  {json_format}\n",
    "                              \n",
    "                      \n",
    "  \"\"\"\n",
    "  \n",
    "  return text\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_api_call(image: base64, entities: list):\n",
    "  \n",
    "  client = OpenAI(api_key=api_key)\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": build_prompt(entities)\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{image}\"\n",
    "            }\n",
    "          \n",
    "          },\n",
    "        ],\n",
    "      }\n",
    "    ],\n",
    "    max_tokens=800,\n",
    "  )\n",
    "      \n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "718it [52:20,  4.37s/it]\n"
     ]
    }
   ],
   "source": [
    "json_path = data_dir.parent / f'ocr_data_openai.json'\n",
    "\n",
    "ocr_data = json.loads(open(json_path, \"r\").read())\n",
    "\n",
    "test_only_df = combined_df[combined_df[\"dataset\"] == \"test\"]\n",
    "\n",
    "for sentence, entities, image, image_path in tqdm(zip(test_only_df[\"sentence\"].tolist(), test_only_df[\"word\"], \n",
    "                                            test_only_df[\"image\"].tolist(), test_only_df[\"image_path\"].tolist())):  #\n",
    "    \n",
    "#    if not image in ocr_data.keys(): \n",
    "        \n",
    "        encoded_image = encode_image(image_path)\n",
    "        try:\n",
    "            content = send_api_call(encoded_image, entities)\n",
    "            ocr_data[image] = content\n",
    "        except:\n",
    "            ocr_data[image] = \"API Error\"\n",
    "            \n",
    "            # Save the OCR data after each iteration\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(ocr_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6716/6716 [00:00<00:00, 68630.76it/s]\n"
     ]
    }
   ],
   "source": [
    "ocr_data_cleaned = dict()\n",
    "error_data = dict()\n",
    "\n",
    "for k, v in tqdm(ocr_data.items()):\n",
    "    try:\n",
    "        keys_filtered_a = \"{\"+\"{\".join(ocr_data[k].split(\"{\")[1:])\n",
    "        keys_filtered_b = (\"\".join(keys_filtered_a.split(\"}\")[:-1]) + \"}\" + \"}\").replace('\"IMAGE_DESCRIPTION:', '\"IMAGE_DESCRIPTION\":')\n",
    "        ocr_data_cleaned[k] = dict_obj = ast.literal_eval(keys_filtered_b)\n",
    "    except:\n",
    "        error_data[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_filtered = data_dir.parent / f'ocr_data_openai_preprocessed.json'\n",
    "\n",
    "with open(json_path_filtered, 'w') as f:\n",
    "    json.dump(ocr_data_cleaned, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
